\documentclass[12pt]{article}

\usepackage{notestyle}

\graphicspath{{./img/}}


\title{Appunti Architettura}
\author{Brendon Mendicino}



\begin{document}

\maketitle
\newpage
\tableofcontents
\newpage


\section{Introduzione}\label{sec:introduzione}

\section{Pipeline}
Per misurare le prestazioni di una pipeline si usa il \textbf{throughput}. Il throughput \`e il numero di sitruzioni che escono dalla pipeline in un intervallo di tempo.

Il datapath \`e composto da:
\begin{itemize}
    \item instruction fetch: si prende dalla memoria la prossima istruzione putnatata dal PC e si incrementa quest'ultimo di 4;
    \item decode: si decodifica l'istruzione, attivando il datapath in modo adeguato, a prescindere dal tipo di operazione carico i due registri rs ed rt, ed il campo immediato, anche nel caso l'istruzione non fosse immediata, risparmio del tempo aumentando leggermente il comsumo di potenza;
    \begin{itemize}
        \item A <- Reg[rs];
        \item B <- Reg[rt];
        \item Imm <- ($IR_{16\dots 31}$);
    \end{itemize}
    \item execution/effective address cycle: 
        \begin{itemize}
            \item memory reference: ALUoutput <- A + Imm;
            \item register-register: ALUoutput <- A op B;
            \item register-immediate: ALUoutput <- A op Imm;
            \item brach: ALUoutput <- NPC + Imm; Cond <- (A op 0);
        \end{itemize}
    \item memory access/branch completion cycle:
        \begin{itemize}
            \item LMD <- Mem[ALUoutput]; or Mem[ALUoutput] <- B;
            \item branch: if (cond) PC <- ALUoutput else PC <- NPC;
        \end{itemize}
    \item write-back cycle:
        \begin{itemize}
            \item register-register: Reg[$IR_{16\dots 20}$] <- ALUoutput;
            \item ...
        \end{itemize}
\end{itemize}

L'assunzione molto forte sar\`a che tutti i dati e le istruzioni saranno sempre nelle memoria cache, quindi si avr\`a un delay di un solo colpo di clock. Il registre file potr\`a sia essere letto che scritto, ci sar\`a dunque bisogno di soddisfare queste richeste in un solo colpo di clock, la scrittura avviene nella prima parte del colpo di clock mentre la lettura avviene nelle seconda parte del colpo di clock.

Si aggiungono dei registri (detti pipeline register), 

Aggiungere i registri della pipeline aggiunge un overhead, inoltre il clock del processore comporta un rallentamento, causato dallo skew.

\section{Pipeline Hazards}
Sono dei casi in cui l'istruzione non viene esguita in modo corretto:
\begin{itemize}
    \item structural hazards: dipende dalla memoria, 
    \item data hazards: dipende da come i dati vengono scritti e letti;
    \item control hazards: dependi dai branch;
\end{itemize}

\paragraph{Stall}
Un modo di gestire gli hazards \`e di manadre la CPU in stallo.

Risolvere gli hazard strutturali comporta un costo, in termini di nuovo hardware e di migliorare quello esistente. Un processore con hazard strutturali avr\`a un clock pi\`u veloce ma problemi di accesso alla memoria, un processore senza hazard strutturali avr\`a un clock pi\`u lento ma nessuna limitizione di accesso alla memoria.

\paragraph{Data hazards}
Generati dalle dipendenze dei dati generati all'interno della pipeline. Esempio:
\begin{lstlisting}
add r1, r2, r3
sub r4, r1, r5
and r6, r1, r7
or  r8, r1, r9
xor r10, r1, r11
\end{lstlisting}
Il registro r1 viene inizializzato nella prima istruzione e poi utilizzato nel resto del codice, ma l'operazione di scrittura in si trova alla fine, infatti l'istruzione successiva (sub) dovrebbe aspettare che r1 sia scritto prima che possa essere letto, se tuttavia proviamo a leggere r1 il risultato sar\`a non deterministico.

Per risolvere questo problema si hanno due soluzioni:
\begin{itemize}
    \item mandare in stallo il processore;
    \item implementiamo un forwarding che permette di non attendere la scrittura del registro, ma di leggere direttamente il valore dei registri della pipeline;
\end{itemize}


\section{Floating Point}
Le operazioni floating point sono molto complesse, se si cerca di implementarle in un solo colpo di clock allora il processore diventa troppo complicato dal punto di vista logico, oppure un altra suluzione potrebbe essere quello di rallentare il clock, per far entrare tutte le operazioni in un singolo colpo, ma entrambe le soluzioni non sono fattibili, allora si prende un approcia di suddivisione della pipeline in unit\`a. Per supportare le operazioni di floating point in pipeline, si \`e optato per una separazione dalla execute in diverse unit\`a:
\begin{itemize}
    \item integer unit;
    \item fp/integer multiply;
    \item fp adder;
    \item fp/integer divider;
\end{itemize}
Questa ramificazione della pipeline va a convergere nella sezione di MEM.

Si dovr\`a definire la latenza, ovvero il numero di colpi di clock che una unit\`a usa per avere un risultato, ed un intervallo di inizializzazione, ovvero il numero di colpi di clock che la seconda istruzione davr\`a attendere per entrare nella sezione desiderata (come somma o divisione). Un esempio:
\begin{itemize}
    \item add: lat: 1, int: 1;
    \item mult: lat: 8, int: 1;
    \item fadd: lat: 4: 1;
    \item div: lat: 24, int: 24;
\end{itemize}

Solitamente la divisione ha la latenza identica all'intervallo di inizializzazione. Solitamente su un unit\`a \`e \textbf{pipelined} allora ha un colpo di clock come intervallo di inizializzazione, se l'unit\`a non \`e pipelined allora il suo intervallo di inizializzazione \`e uguale alla latenza.


Un altro porblema dato dagli hazard strutturali \`e il fatto che: pi\`u istruzioni non possono accedere in contemporanea alla fase di MEM o di WB, solitamente il criterio \`e FIFO, oppure si potrebbe dare maggiore priorit\`a alla istruzioni con il maggiore numero di clock.




\section{Exceptions}
Le eccezioni sono classificate in:
\begin{itemize}
    \tolerance=1000
    \item \textbf{sincrone} e \textbf{asincrone};
    \item \textbf{user requested} (l'utente potrebbe creare un eccezione) o \textbf{coerced} (data da fattori esterni);
    \item \textbf{maskable} o \textbf{non-maskable}: alcune eccezioni non sono mascherabili ovvero forzare l'hardaware a non rispondere all'exception;
    \item \textbf{within instructions} o \textbf{between instructions}: within all'interno delle istruzioni (metre un istruzione fa DI, ID, ...) oppure tra due istruzinoi (ld, add);
\end{itemize}
Le macchine moderne sono chiamate \textbf{restartable machines} ovvero fanno ripartire il processore dallo stato in cui si trovava prima dell'eccezione. Quando una exception arriva il processore deve stoppare il IF, fermare la scrittura della pipeline e riuscire a tornare dalla procedura che ha chiamato l'exception.

\begin{example}{Interrupt protocal in 80x86}{interrupt-protocal-in-80x86}
    Quando la CPU rileva un interrupt, legge il tipo di interrupt dal bus, salva lo stato del processore
\end{example}

ARM: la CPU salva lo status, il PC ed il Processore Status Register nello stack, aggiorna i flag e salta al valore dell'exception

Le eccezioni possono gestite in modo \textbf{preciso} o in modo \textbf{impreciso}:
\begin{itemize}
    \item preciso: quando avviene un interruzione, tutte le istruzione prima che arrivi l'istruzione devono essere completate, tutte quelle dopo devono essere rimandate, gestire questo tipo di istruzioni \`e molto oneroso;
    \item impreciso: 
\end{itemize}

Nel MIPS le possibili exception sono:
\begin{itemize}
    \item IF: page fault, accesso a memoria protetta;
    \item ID: opcode illegale;
    \item EX: exception aritmetiche;
    \item MEM: stesse della IF;
    \item WB: nussuna;
\end{itemize}
Se due exception arrivano nello stesso momento: si pu\`u creare un flag di status associato ad ogni istruzione, guardande se l'istruzione pu\`o causare un eccezione, quando l'istruzione termina, l'exception viene scatenata, cos\`i si crea un coda evitando exception simultanee.


\section{Chache Memories}
\tolerance=1000
Le cache volocizzano l'accesso al memoria secondaria che \`e il collo di bottiglia dell'intero sistema. Si \`e creata un gerarchia di memorie molto pi\`u veloci quanto pi\`u vicine si trovano al processore.
\begin{itemize}
    \item reigistri: 500 bytes, 500ps;
    \item L1: 64 KB, 2ns;
    \item L2: 256 KB, 10-20ns;
    \item Memoria primaria: 512 MB, 50-100ns;
    \item Memoria secondaria flash: 8 GB, 50$\mu$s;
\end{itemize}
La cache funzionano grazie ai principi di localit\`a:
\begin{itemize}
    \item temporale: in un tempo $t_0 + \Delta t$ dal momento in cui ho letto un elemento, \`e probabile che il dato venga o l'istruzioe venga riusato;
    \item spaziale: in un spazio $x + \Delta x$ vicino all'elemento letto, \`e probabile che gli elementi vicini vengano letti;
\end{itemize}

\begin{theorem}{Cache Performance}{cache-performance}
    \begin{itemize}
        \item h: cache ratio;
        \item C: cache access time;
        \item M: memory access time;
    \end{itemize}
    Media del tempo di accesso:
    \[ t_{ave} = h * C + (1-h) * M \]
    Valori soliti per $h$ sono $0.9$.
\end{theorem}

\paragraph{Organizzazione della cache}
Solitamente la cache \`e formata da una parte di contrllo contenente il \textbf{cache controller} che controlla se accedendo alla cache \`e stato fatto un hit o un miss e in caso recupera la porzione di memoria ed una parte di dati, che contiene le \textbf{cache line} fatte da:
\begin{itemize}
    \item validity bit: il bit ci dice se la riga \`e valida o meno;
    \item tag: identifica il blocco di memoria presente nella riga;
    \item data array: contiene i dati presi dalla memoria;
\end{itemize}
A partire dall'indirizzo la cache si calcola un nuovo indirizzo di accesso alle righe, foramto da:
\begin{itemize}
    \item tag: identifica il blocco di memoria (bit dell'indirizzo - bit index - bit offset);
    \item index: riga della cache;
    \item offset: byte offset all'interno della riga;
\end{itemize}
Per regolare l'accesso alla cache il controllore identifica la riga attraverso l'index e comparando i due tag decide se \`e un hit o un miss, se \`e un hit ed il validity bit \`e a 1, allora attraverso l'offset viene prelevato il dato.

La cache si trovano tra il bus ed il processore, per evitare conflitti di utilizzo con perfiriferiche esterne o DMA.

Le cache moderne pi\`u vicine al processore sono separtate in \textbf{Instruction-Cache} e \textbf{Data-cache}, per evitare la lettura contemporanea di istruzioni e dati (structural hazard).

\paragraph{Mappatura}
I tipi di mappatura (\textbf{associativity models}) sono:
\begin{itemize}
    \item \textbf{direct mapped}: la posizione nella riga \`e uguale a: \#block\_memory mod \#cache\_block;
    \item \textbf{set associative}: la cache viene partizionata in set di righe (i blocchi hanno tutti la stessa lunghezza, tipicamente 2 o 4), la posizione \`e determinata da: \#memory\_block mod \#sets, quando un altro blocco viene asseganto ad un set viene rimossa la riga meno utilizzata;
    \item \textbf{fully associative}: ogni blocco di memoria pu\`o essere salvata in qualsiasi riga della cache, questo ha come malus la perdita del compo index e l'indirizzo del blocco viene salvato per intero;
\end{itemize}

\paragraph{Algoritmi di rimpiazzamento}
Gli aloritmi usati per decidere quale riga rimpiazzare sono:
\begin{itemize}
    \item LRU (last recently used): il pi\`u usato;
    \item FIFO: il meno caro in termini di prestazioni;
    \item LFU (least frequently used): teorico, il pi\`u efficace;
    \item random: semplice ed efficace;
\end{itemize}

\paragraph{Update della Memoria}
Quando un operazione di scrittura \`e fatta sulla cache deve anche essere propagata sulla memoria, le due possibili soluzioni a questo problema sono:
\begin{itemize}
    \item \textbf{write back}: per ongi riga della cache \`e introdotto un flag detto \textbf{dirty bit}, che indica quando i dati all'interno sono cambiati;
    \item \textbf{write through}: ogni volta che la CPU effettua un operazione di scrittura, i dati vengono scritti sia in cach e che in memoria;
\end{itemize}


\section{BPU}
...


\subsection{BHT}
Un tipo di predittore dinamico: \`e una piccola memoria che salva per ogni istruzione salva dei valori
funzionamento:
\begin{itemize}
    \item se un branch non viene effettuta il contatore misP. counter ed il BHT vengono incrementati, il miss viene incrementato fino ad un massimo di differenza con il BHT, superato questo threshold i contatori non vengono incrementati ed il branch prediction \`e attivato per quella istruzione;
    \item se un branch viene effettuato il BHT viene decrementatto, se il BHT \`e minore del miss il branch prediction non viene attivato per quella istruzione;
\end{itemize}





\end{document}
