\documentclass[12pt]{article}

\usepackage{notestyle}

\graphicspath{{./img/}}


\title{Appunti Architettura}
\author{Brendon Mendicino}



\begin{document}

\maketitle
\newpage
\tableofcontents
\newpage


\section{Introduzione}\label{sec:introduzione}

\section{Pipeline}
Per misurare le prestazioni di una pipeline si usa il \textbf{throughput}. Il throughput \`e il numero di sitruzioni che escono dalla pipeline in un intervallo di tempo.

Il datapath \`e composto da:
\begin{itemize}
    \item instruction fetch: si prende dalla memoria la prossima istruzione putnatata dal PC e si incrementa quest'ultimo di 4;
    \item decode: si decodifica l'istruzione, attivando il datapath in modo adeguato, a prescindere dal tipo di operazione carico i due registri rs ed rt, ed il campo immediato, anche nel caso l'istruzione non fosse immediata, risparmio del tempo aumentando leggermente il comsumo di potenza;
    \begin{itemize}
        \item A <- Reg[rs];
        \item B <- Reg[rt];
        \item Imm <- ($IR_{16\dots 31}$);
    \end{itemize}
    \item execution/effective address cycle: 
        \begin{itemize}
            \item memory reference: ALUoutput <- A + Imm;
            \item register-register: ALUoutput <- A op B;
            \item register-immediate: ALUoutput <- A op Imm;
            \item brach: ALUoutput <- NPC + Imm; Cond <- (A op 0);
        \end{itemize}
    \item memory access/branch completion cycle:
        \begin{itemize}
            \item LMD <- Mem[ALUoutput]; or Mem[ALUoutput] <- B;
            \item branch: if (cond) PC <- ALUoutput else PC <- NPC;
        \end{itemize}
    \item write-back cycle:
        \begin{itemize}
            \item register-register: Reg[$IR_{16\dots 20}$] <- ALUoutput;
            \item ...
        \end{itemize}
\end{itemize}

L'assunzione molto forte sar\`a che tutti i dati e le istruzioni saranno sempre nelle memoria cache, quindi si avr\`a un delay di un solo colpo di clock. Il registre file potr\`a sia essere letto che scritto, ci sar\`a dunque bisogno di soddisfare queste richeste in un solo colpo di clock, la scrittura avviene nella prima parte del colpo di clock mentre la lettura avviene nelle seconda parte del colpo di clock.

Si aggiungono dei registri (detti pipeline register), 

Aggiungere i registri della pipeline aggiunge un overhead, inoltre il clock del processore comporta un rallentamento, causato dallo skew.

\section{Pipeline Hazards}
Sono dei casi in cui l'istruzione non viene esguita in modo corretto:
\begin{itemize}
    \item structural hazards: dipende dalla memoria, 
    \item data hazards: dipende da come i dati vengono scritti e letti;
    \item control hazards: dependi dai branch;
\end{itemize}

\paragraph{Stall}
Un modo di gestire gli hazards \`e di manadre la CPU in stallo.

Risolvere gli hazard strutturali comporta un costo, in termini di nuovo hardware e di migliorare quello esistente. Un processore con hazard strutturali avr\`a un clock pi\`u veloce ma problemi di accesso alla memoria, un processore senza hazard strutturali avr\`a un clock pi\`u lento ma nessuna limitizione di accesso alla memoria.

\paragraph{Data hazards}
Generati dalle dipendenze dei dati generati all'interno della pipeline. Esempio:
\begin{lstlisting}
add r1, r2, r3
sub r4, r1, r5
and r6, r1, r7
or  r8, r1, r9
xor r10, r1, r11
\end{lstlisting}
Il registro r1 viene inizializzato nella prima istruzione e poi utilizzato nel resto del codice, ma l'operazione di scrittura in si trova alla fine, infatti l'istruzione successiva (sub) dovrebbe aspettare che r1 sia scritto prima che possa essere letto, se tuttavia proviamo a leggere r1 il risultato sar\`a non deterministico.

Per risolvere questo problema si hanno due soluzioni:
\begin{itemize}
    \item mandare in stallo il processore;
    \item implementiamo un forwarding che permette di non attendere la scrittura del registro, ma di leggere direttamente il valore dei registri della pipeline;
\end{itemize}


\section{Floating Point}
Le operazioni floating point sono molto complesse, se si cerca di implementarle in un solo colpo di clock allora il processore diventa troppo complicato dal punto di vista logico, oppure un altra suluzione potrebbe essere quello di rallentare il clock, per far entrare tutte le operazioni in un singolo colpo, ma entrambe le soluzioni non sono fattibili, allora si prende un approcia di suddivisione della pipeline in unit\`a. Per supportare le operazioni di floating point in pipeline, si \`e optato per una separazione dalla execute in diverse unit\`a:
\begin{itemize}
    \item integer unit;
    \item fp/integer multiply;
    \item fp adder;
    \item fp/integer divider;
\end{itemize}
Questa ramificazione della pipeline va a convergere nella sezione di MEM.

Si dovr\`a definire la latenza, ovvero il numero di colpi di clock che una unit\`a usa per avere un risultato, ed un intervallo di inizializzazione, ovvero il numero di colpi di clock che la seconda istruzione davr\`a attendere per entrare nella sezione desiderata (come somma o divisione). Un esempio:
\begin{itemize}
    \item add: lat: 1, int: 1;
    \item mult: lat: 8, int: 1;
    \item fadd: lat: 4: 1;
    \item div: lat: 24, int: 24;
\end{itemize}

Solitamente la divisione ha la latenza identica all'intervallo di inizializzazione. Solitamente su un unit\`a \`e \textbf{pipelined} allora ha un colpo di clock come intervallo di inizializzazione, se l'unit\`a non \`e pipelined allora il suo intervallo di inizializzazione \`e uguale alla latenza.


Un altro porblema dato dagli hazard strutturali \`e il fatto che: pi\`u istruzioni non possono accedere in contemporanea alla fase di MEM o di WB, solitamente il criterio \`e FIFO, oppure si potrebbe dare maggiore priorit\`a alla istruzioni con il maggiore numero di clock.




\section{Exceptions}
Le eccezioni sono classificate in:
\begin{itemize}
    \tolerance=1000
    \item \textbf{sincrone} e \textbf{asincrone};
    \item \textbf{user requested} (l'utente potrebbe creare un eccezione) o \textbf{coerced} (data da fattori esterni);
    \item \textbf{maskable} o \textbf{non-maskable}: alcune eccezioni non sono mascherabili ovvero forzare l'hardaware a non rispondere all'exception;
    \item \textbf{within instructions} o \textbf{between instructions}: within all'interno delle istruzioni (metre un istruzione fa DI, ID, ...) oppure tra due istruzinoi (ld, add);
\end{itemize}
Le macchine moderne sono chiamate \textbf{restartable machines} ovvero fanno ripartire il processore dallo stato in cui si trovava prima dell'eccezione. Quando una exception arriva il processore deve stoppare il IF, fermare la scrittura della pipeline e riuscire a tornare dalla procedura che ha chiamato l'exception.

\begin{example}{Interrupt protocal in 80x86}{interrupt-protocal-in-80x86}
    Quando la CPU rileva un interrupt, legge il tipo di interrupt dal bus, salva lo stato del processore
\end{example}

ARM: la CPU salva lo status, il PC ed il Processore Status Register nello stack, aggiorna i flag e salta al valore dell'exception

Le eccezioni possono gestite in modo \textbf{preciso} o in modo \textbf{impreciso}:
\begin{itemize}
    \item preciso: quando avviene un interruzione, tutte le istruzione prima che arrivi l'istruzione devono essere completate, tutte quelle dopo devono essere rimandate, gestire questo tipo di istruzioni \`e molto oneroso;
    \item impreciso: 
\end{itemize}

Nel MIPS le possibili exception sono:
\begin{itemize}
    \item IF: page fault, accesso a memoria protetta;
    \item ID: opcode illegale;
    \item EX: exception aritmetiche;
    \item MEM: stesse della IF;
    \item WB: nussuna;
\end{itemize}
Se due exception arrivano nello stesso momento: si pu\`u creare un flag di status associato ad ogni istruzione, guardande se l'istruzione pu\`o causare un eccezione, quando l'istruzione termina, l'exception viene scatenata, cos\`i si crea un coda evitando exception simultanee.


\section{Chache Memories}
\tolerance=1000
Le cache volocizzano l'accesso al memoria secondaria che \`e il collo di bottiglia dell'intero sistema. Si \`e creata un gerarchia di memorie molto pi\`u veloci quanto pi\`u vicine si trovano al processore.
\begin{itemize}
    \item reigistri: 500 bytes, 500ps;
    \item L1: 64 KB, 2ns;
    \item L2: 256 KB, 10-20ns;
    \item Memoria primaria: 512 MB, 50-100ns;
    \item Memoria secondaria flash: 8 GB, 50$\mu$s;
\end{itemize}
La cache funzionano grazie ai principi di localit\`a:
\begin{itemize}
    \item temporale: in un tempo $t_0 + \Delta t$ dal momento in cui ho letto un elemento, \`e probabile che il dato venga o l'istruzioe venga riusato;
    \item spaziale: in un spazio $x + \Delta x$ vicino all'elemento letto, \`e probabile che gli elementi vicini vengano letti;
\end{itemize}

\begin{theorem}{Cache Performance}{cache-performance}
    \begin{itemize}
        \item h: cache ratio;
        \item C: cache access time;
        \item M: memory access time;
    \end{itemize}
    Media del tempo di accesso:
    \[ t_{ave} = h * C + (1-h) * M \]
    Valori soliti per $h$ sono $0.9$.
\end{theorem}

\paragraph{Organizzazione della cache}
Solitamente la cache \`e formata da una parte di contrllo contenente il \textbf{cache controller} che controlla se accedendo alla cache \`e stato fatto un hit o un miss e in caso recupera la porzione di memoria ed una parte di dati, che contiene le \textbf{cache line} fatte da:
\begin{itemize}
    \item validity bit: il bit ci dice se la riga \`e valida o meno;
    \item tag: identifica il blocco di memoria presente nella riga;
    \item data array: contiene i dati presi dalla memoria;
\end{itemize}
A partire dall'indirizzo la cache si calcola un nuovo indirizzo di accesso alle righe, foramto da:
\begin{itemize}
    \item tag: identifica il blocco di memoria (bit dell'indirizzo - bit index - bit offset);
    \item index: riga della cache;
    \item offset: byte offset all'interno della riga;
\end{itemize}
Per regolare l'accesso alla cache il controllore identifica la riga attraverso l'index e comparando i due tag decide se \`e un hit o un miss, se \`e un hit ed il validity bit \`e a 1, allora attraverso l'offset viene prelevato il dato.

La cache si trovano tra il bus ed il processore, per evitare conflitti di utilizzo con perfiriferiche esterne o DMA.

Le cache moderne pi\`u vicine al processore sono separtate in \textbf{Instruction-Cache} e \textbf{Data-cache}, per evitare la lettura contemporanea di istruzioni e dati (structural hazard).

\paragraph{Mappatura}
I tipi di mappatura (\textbf{associativity models}) sono:
\begin{itemize}
    \item \textbf{direct mapped}: la posizione nella riga \`e uguale a: \#block\_memory mod \#cache\_block;
    \item \textbf{set associative}: la cache viene partizionata in set di righe (i blocchi hanno tutti la stessa lunghezza, tipicamente 2 o 4), la posizione \`e determinata da: \#memory\_block mod \#sets, quando un altro blocco viene asseganto ad un set viene rimossa la riga meno utilizzata;
    \item \textbf{fully associative}: ogni blocco di memoria pu\`o essere salvata in qualsiasi riga della cache, questo ha come malus la perdita del compo index e l'indirizzo del blocco viene salvato per intero;
\end{itemize}

\paragraph{Algoritmi di rimpiazzamento}
Gli aloritmi usati per decidere quale riga rimpiazzare sono:
\begin{itemize}
    \item LRU (last recently used): il pi\`u usato;
    \item FIFO: il meno caro in termini di prestazioni;
    \item LFU (least frequently used): teorico, il pi\`u efficace;
    \item random: semplice ed efficace;
\end{itemize}

\paragraph{Update della Memoria}
Quando un operazione di scrittura \`e fatta sulla cache deve anche essere propagata sulla memoria, le due possibili soluzioni a questo problema sono:
\begin{itemize}
    \item \textbf{write back}: per ongi riga della cache \`e introdotto un flag detto \textbf{dirty bit}, che indica quando i dati all'interno sono cambiati;
    \item \textbf{write through}: ogni volta che la CPU effettua un operazione di scrittura, i dati vengono scritti sia in cach e che in memoria;
\end{itemize}


\newpage
\section{Branch Prediction}
Per effettuare delle predizioni esistono due tipi di approcci: prediction statici e prediction dinamici. Un esempio prediction statico \`e prendere tutti i salti come presi, oppure facciamo un filtro su quali tipi di branch prendere come presi (prendere i salti all'indietro come sempre presi).

Per avere delle predizioni pi\`u accurate \`e usare un brach prediction dinamico (speculazione). I metodi di predizione sono:
\begin{itemize}
    \item branch history table;
\end{itemize}

\paragraph{Branch History Table}
Il BHT ha una memoria in cui sono contenute le informazioni relative ai salti. Si accede a questa tabella quando nella fase di fetch si prende un salto, si guarda l'informazione relativa e al salto e si legge la predizione del salto.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{bht-implementation.png}
    \caption{Bht Implementation}
    \label{fig:bht-implementation}
\end{figure}
Solitamente il valore che indica se il branch deve essere preso o meno solitamente \`e reppresentato da due bit.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{two-bits-prediction-scheme.png}
    \caption{Two Bits Prediction Scheme}
    \label{fig:two-bits-prediction-scheme}
\end{figure}
Questi tipi di predittori sono stati evoluti, usando dei contatori (\textbf{n-bit saturating counter}), quando un salto viene preso il contatore aumenta altrimenti diminuisce, se il bit pi\`u significativo \`e settato ad 1 allora il branch viene preso, questo tipo di contatore di saturazione \`e molto facile da implementare.

Altri tipi di predittori sono i \textbf{(m, n) predictors} guardano agli m-salti precedenti, date le $2^{m}$ possibili salti ognuno ha un predittore da n bit.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{predictor.png}
    \caption{(2,2) Predictor}
    \label{fig:predictor}
\end{figure}
Questi tipi di predittori non danno inforamazioni su dove saltare.

Un altro predittore \`e il \textbf{Branch Target Buffer} (usato dal MIPS), questo tipo di predettore ha a disposizine dei registri in cui sono contenuti gli indirizzi di salto, questo struttura contiene l'indirizzo del salto attuale, viene interrogata durante la fase di fetch e sar\`a poi disponibili al secondo colpo di clock, nel colpo di clock successivo l'indirizzo viene letto, se l'istruzione \`e un branch e l'istruzione corrente si trova nella tabella, allora il salto deve essere preso, per ogni linea si devo salvare 30bit per indirizzo (vengono tagliati gli ultimi 2 essendo degli indirizzi). Il problema con questo predittore \`e che \`e molto costoso, infatti si deve avare un numero di entry non piccolo che che sono onerose in termini di memoria.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{comportamento-branch-target-buffer.png}
    \caption{Comportamento Branch Target Buffer}
    \label{fig:comportamento-branch-target-buffer}
\end{figure}

Esistono anche due tipi di predittori chiamati \textbf{gselect} e \textbf{gshare}.

\begin{example}{BHT}{bht}
    
\end{example}

\newpage
\section{Schedulazione Dinamica}



\newpage
\section{Pipelining}
Esistono delle tecniche per portare le CPI sotto il numero 1, questo \`e possibile farlo attraverso il fetch di pi\`u istruzioni. Esistono due tipi di processori che possono farlo:
\begin{itemize}
    \item \textbf{superscalari}: hanno uno scheduling statico o dinamico;
    \item \textbf{very long instruction word (VLIW)};
\end{itemize}


\subsection{Static Scheduling}
Per implementare un processore superscalare viene creato un \textbf{issue packet}, dove viene fatto il fetch di due (o pi\`u) istruzioni contemporaneamente se in modo statico: una \`e load, store, branch o operazioni ALU e l'altra \`e una qualsiasi operazione FP, queste due istruzioni vengono chimate issue packet.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{issue-packet-example.png}
    \caption{Issue Packet Example}
    \label{fig:issue-packet-example}
\end{figure}
In un caso ideale si eseguiranno 0.5 istruzioni per colpo di clock. L'issue packet conterr\`a sempre una sola istruzione di branch. In questo caso l'unit\`a FP sar\`a pipelined o indipendente, in qualche modo \`e possibile ottere degli hazard, come: fare un un istruzione di load e subito dopo un'istruzione di write, oppure dei possibili RAW (read after write).

Nei sistemi moderni si utilizza una strategia statica in alcuni processori embedded con MIPS.


\subsection{Dynamic Scheduling}
Si pu\`o ottenere una schedulazione dinamica
Si ha un Common Data Bus (sistema di forwarding) comune, quindi viene duplicato. Suppoiamo di avere le seguenti istruzioni:
\begin{lstlisting}[language=]
loop:
    ls r2, 0(r1)
    daddiu r2, r2, 1
    sd r2, 0(r1)
    daddiu r1, r1, 4
    bne r2, r3, loop
\end{lstlisting}
Supponiamo che:
\begin{itemize}
    \item non ci sia speculazione:
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\textwidth]{dynamic-scheduling-senza-speculazione.png}
        \caption{Dynamic Scheduling Senza Speculazione}
        \label{fig:dynamic-scheduling-senza-speculazione}
    \end{figure}
    \item con speculazione:
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.8\textwidth]{dynamic-scheduling-con-speculazione.png}
            \caption{Dynamic Scheduling Con Speculazione}
            \label{fig:dynamic-scheduling-con-speculazione}
        \end{figure}
\end{itemize}



\newpage
\section{ARM}
Nei lab verr\`a usato il \textbf{Coretex M3} che fa parte di ARM9. ARM sviluppa architetture per tre categorie:
\begin{itemize}
    \item architetture embedded (SoC: system on a chip);
    \item sistem operativi;
    \item compilazione - supporto - debug tools
\end{itemize}


Uno dei moduli \`e il \textbf{Memory BIST}: questi parti del SoC servono per il collaudo del sistema, infatti duranta la pruduzione sul silicio le momoria potrebbere avere dei problemi fisici (quando si scrive in un registro il valore savato non \`e corretto o potrebbe intaccare quello dei registri vicini), infatti questi moduli non interagiscono direttamente con la logica del processore.

In un dispositivo ARM compliant la prima parte di codice che viene eseguita \`e il bootloader, per poi far partire il sistema operativo. Guadando la toochain, si parte dal codice assembly ARM, e dal codice C/C++, questi verranno compilati da un CROSS COMPILER, il risultato finala sar\`a un codice compilato con un ISA per ARM. Il risulatato sar\`a un eseguibile, con questo eseguibile sar\`a possibile usarlo in un simulatore di una scheda oppure caricarlo direttamente sulla scheda.


ARM cortex-M3 contiene 16 registri, tra cui il 15 \`e il PC. Il \textbf{barrel shifter} si avr\`a la possibilit\`a di creare valori immediati fino a 32 bit, sole se il valore contiene in qualche modo un replicazione all'interno di se stesso, inoltre ci permette di fare uno shift automatico del secondo registro su cui stiamo operando salvando un'istruzione.

Esistono alcuni casi particolari:
\begin{itemize}
    \item istruzioni \textbf{registro-registro}: dati i due registri Rn ed Rm, il primo entra direttamente nell'ALU, il secondo pu\`o essere modificato, al termine dell'operazione il risultato viene riportaro in un registro;
    \item ...
\end{itemize}


I vari moduli sono:
\begin{itemize}
    \item nested vectored interrupt controller;
    \item wake up interrupt controller interface: permette di mandare il dispositivo in sleep;
    \item memoria: interface code, memeory protection unit;
    \item SRAM e interfaccie periferiche: possibilit\`a di parlare con i timer;
    \item debug access port: permette di effettuare il debug anche attraverso il codice;
    \item ITM trace, ETM trace, data watchpoint, flash patch: moduli che permettono di fare il debug;
\end{itemize}

La pipeline \`e formata da:
...

Le istruzioni di branch comportano una perdita di due cicli. Quando si legge dalla memoria si perde un colpo di clock.

\subsection{Register}
Non tutti i registri sono general purpose, infatti:
\begin{itemize}
    \item 15: PC;
    \item 14: link register;
    \item 13: stack pointer: l'sp ha due versinoi;
\end{itemize}

L'instruction set utilizzato sar\`a il \textbf{thumb 2}, che prende le caratteristiche positive del thumb (a 16 bit) e dell'ARM, in thumb 2 esistono istruzioni a 16 e 32 bit, in questo modo i programmi sono pi\`u piccoli e le prestazioni sono simili all'ARM.

...

Ogni istruzione pu\`o essere eseguita in modo condizionato. L'architettura load e store si pu\`o utilizzare un formato di tre operandi.


\subsection{Instruction Set}
In questa architettura il PC \`e immagazzinato in r15, questo registro \`e modificabile, modificare il PC \`e importante quando ad esempio si ritorna da un subroutine, il registro r14 link register salva il valore di memoria di ritorno che andr\`a copiato nel PC. Il registro r13 \`e lo stack pointer, che permette di avere il valore dell'ultimo oggetto inserito, questo registro ha un valore iniziale, al termine del programma il valore dello stack pointer var\`a ricaricato con il suo valore iniziale che si trova all'interno della \textbf{interrupt vector table}, la posizione dello stack precedente si trova nell'index 0. Esiste anche il program status register \`e deviso in 3 registri, a seconda dell'operazione che si sta facendo si potrebbe accedere solo ad un parte del registro, vi sono dei flag delle operazioni aritmetiche, questo registro \`e diviso in:
\begin{itemize}
    \item application program status regiser (apsr);
    \item execution program status register (epsr);
    \item interrupt porgram status register (ipsr);
\end{itemize}

I flag sono:
\begin{itemize}
    \item Z zero;
    \item N negative;
    \item C carry;
    \item V overflow;
\end{itemize}

L'esecuzione condizionata delle istruzioni non vale solo per i salti, ma per ogni istruzione, nei 32 bit delle istruzioni ARM (comprese nella versione thumb 2), si hanno 4 bit che indicano il tipo di condizione che determina se l'istruzione viene eseguita oppure no, questo viene fatto leggendo i flag o secondo certe condizioni. Se si vuole che un istruzione modifichi un flag dobbiamo chiderlo esplicitamente, aggiungendo un \textbf{S} alla fine dell'istruzione.


v5.36 di Keil








\end{document}
