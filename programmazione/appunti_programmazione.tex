\documentclass[12pt]{article}

\usepackage{notestyle}

\graphicspath{{./img/}}


\title{Notes Software Engineering}
\author{Brendon Mendicino}



\begin{document}

\maketitle
\newpage
\tableofcontents
\newpage




\section{Memoria}
La memoria si compone si suddivide in:
\begin{itemize}
  \item registri;
  \item cache
  \item memoria primaria;
  \item memoria secondaria;
\end{itemize}
Uno principali problemi di accesso alla memoria \`e quello di assicurarne la sua protezione, ovvero evitare che un programma in memoria riesca ad accedere alle zone di memoria di altri programmi. Una volta fatto il bootstrap del SO, sia esso che i programmi verranno caricati in memoria, per evetire che ogni processo abbia una vista al di fuori del suo scope, si possono usare dei controlli a livello della CPU, esistono dei registri chimati \textbf{base} e \textbf{limit}, che attraverso dei meccanismi, riescono ad effettuare la protezione della memoria. Esiste anche un altro problema che \`e quello \textbf{relocation}, consiste nel come mappare gli indirizzi delle varie istruzioni di salto e dei vari puntari una volta che il programma viene caricato in memoria, se si utilizzaro degli indirizzi statici (creati solo in fase di compilazione e prendondo come riferimento di inizio del programma l'indirizzo 0), una volta che questo viene caricato in memoria le istrizioni non punterebbero pi\`u alle label corrispondenti  ma sempre nello stesso punto, dove ad esempio si trova un altro programma. Per questo motivo quando si utilizzano valori di registri vengono sommati al base register, mentre le boundry del programma in memoria vengono salvate nel limit.
% TODO:  <27-02-23, yourname> rivedere %
Binding ...
Si fa:
\begin{itemize}
  \item \textbf{in compilazione}: fatto quando molto semplice, ad esempio quando esistono solo due programmi;
  \item \textbf{in fase di load}: viene fatta la rilocazione durante il caricamento in memoria;
  \item \textbf{in esecuzione}: viene fatto il binding degli indirizzi in modo dinamico;
\end{itemize}
Per risolver questo problema ci si affida all'hardware, che \`e incaricato di fare la traduzione: l'indirizzo rimane lo stesso (logico) all'interno del processore, prima di arrivare all'address bus viene tradotto in indirizzo fisico, esiste dunque una dicotomia di indirizzo logico e fisico, in questo modo quando si scrive un programma, l'indirizzo parte sempre da 0. Esistono due tipi di indirizzamento che sono di tipo logico, dove l'intervallo degli indirizzi utilizzabili \`e logico, ed un indirizzamento fisico, dove il range \`e limitato dalla memoria del sistema. Per effettuare questa traduzione da indirizzo fisico a indirizzo logico e viceversa si utilizza una \textbf{MMU} (Memory Management Unit). Il modo pi\`u facile per realizzare una MMU, \`e quello di usare un \textbf{relocation register}, ovvero un registro che contiene il valore da aggiungere un indirizzo logico per fare un indirizzo fisico, il modello pi\`u semplice di MMU \`e fatto da un sommatore ed un comparatore.

Per aumentare le prestazioni ed usare la memoria in modo pi\`u efficente si possono usare delle tecniche dinamiche.
\begin{itemize}
  \tolerance=1000
  \item Si parla di \textbf{dynamic loading} quando, un programma viene caricato in memoria principale in modo frammentato, utilizzando solo i componenti che effettivamento vengono chiamati;
  \item Si parla di \textbf{dynamic linking} quando i file che contengono le funzioni che devono essere linkate (come le librerie standard) non vengono inserite all'interno dell'eseguibile, ma gli indirizzi vengono risolti in modo dinamico durante l'esecuzione;
  \item Il \textbf{link statico} \`e quando si crea un eseguibile con tutte le funzioni dentro, di fatto il loader carica tutto quando in memoria.
\end{itemize}
Il \textbf{dynamic loading} vuol dire che una routine non \`e caricata finch\'e non \`e necessaria, questo pu\`o essere fatto quando il programmatore ne \`e consapevole, infatti il processo di load non \`e trasparente:
\begin{lstlisting}[language=c]
void myPrinf(**args) {
  static int loaded = 0;
  if (!loaded) {
    load("printf");
    loaded = 1;
  }
  printf(args);
}
\end{lstlisting}
% TODO:  <27-02-23, yourname> rivedere %
Il \textbf{linker-assisted DL} si usa una chiamata fasulla che prima chiama la load, usando una \textbf{stub}.

Le \textbf{shared libraries} sono in grado di condividere le risorse, infatti se pi\`u processi utilizzano la stessa funzione essa viene messa a disposizione e per ogni nuova chiamata non ci sar\`a bisogno di chiamre una load.


Come si alloca memoria per un programma (immagine)? La pi\`u semplice \`e l'allocazoine contigua, dove si vede la RAM come due partizioni, una per il SO una per i processi (indirizzi pi\`u alti), per caricare un processo si parte da un indirizzo di inzio ed un indirizzo di fine, la MMU vista prima funziona solo con i casi di allocazione contigua (basilare). L'\textbf{allocazione contigua con paritizione variabile}: quando ci sono pi\`u buchi ci sono delle politiche differnti per inserire nuovi programmi:
\begin{itemize}
  \item \textbf{first-fit}: il primo che si trova;
  \item \textbf{best-fit}: il buco con la dimensione pi\`u piccola;
  \item \textbf{worst-fit}: il buco can li dimesnione pi\`u grande;
\end{itemize}
La frammentazione \`e sparsit\`a dei buchi all'interno della memoria. Si dice \textbf{esterna} perch\'e \`e al di fuori dei processi, si dice \textbf{interna} quando \`e interna al processo, ovvero che ha pi\`u memoria di quello che serve. La frammentazione ha bisongo di \textbf{compattazione}, il SO sposta i pezzi e poi si riparte, partitione della memoria in zona libera e zona occuputa, per fare una \textbf{deframmentazoine} (o compattazione) voul di re creare solo due partizioni (parte processi e zona libera), per effettuare la compattazione bisogna che i processi si possano spostare, inoltre un processo non pu\`o essere spostato se in quel momento il processo sta effettuando delle operazioni di IO, una soluzione per il problema dell'IO \`e il \textbf{latch job} in cui quella parte non pu\`o essere spostata, oppure si utilizza un \textbf{buffer IO del kernel}, si fa IO solo in buffer del sistema operativo.

\tolerance=1000
Con \textbf{backing store} si definisce uno spazio della memoria secondaria in cui non si salvano programmi ma vengono immagazzinati dei dati che altrimenti dovrebbero andare in RAM.

La \textbf{Paginazione} risolve i problemi della allocazione continua, rimuovendo l'allocazione contigua al suo posto si utilizzano della pagine, che sono l'unit\`a minima di allocazione, questo risolve il problema della frammentazione.
\begin{definition}{Pagine}{pagine}
  Le partizioni della memoria logica.
\end{definition}
\begin{definition}{Frame}{frame}
  Le partizioni della memoria fisica.
\end{definition}
\begin{definition}{Blocco}{blocco}
  ...
\end{definition}
Tipicamente la loro dimensione \`e un multiplo di due, sia pagine che frame hanno la stessa dimensione, da qualche parte andranno salvate le informazioni di mapping tra pagine e frame, si utilizza un \textbf{frame table}, dove ogni riga corrisponde una mappatura. Anche utilizzando la paginazione si ha frammentazione interna, l'ultima pagina soffrir\`a di frammentazione.

% TODO:  <28-02-23, yourname> rivedere, prendere immagini %
Una indirizzo generato dall CPU si divide in:
\begin{itemize}
  \item \textbf{numero di pagine (p)}: 
  \item \textbf{numro di offset (d)}:
  \item \textbf{numero di frame (f)}:
\end{itemize}
Un indirizzo \`e composto da: (p-d, d)
\begin{example}{}{}
  Se si hanno frame piccoli diminuisce la frammentazione ma aumentano anche le righe della tabella.
\end{example}
Nelle righe della tabelle si aggiungono dei bit in pi\`u:
\begin{itemize}
  \item parte di protezione, specifica che la parte di codice non pu\`o essere scritta;
  \item \textbf{modify bit}: pagina modifica;
  \item \textbf{page present/absent}: 
\end{itemize}
Come si implementa una page table? La page table si trova in memoria RAM, per sapere dove si trova si utilizzano due rigistri: \textbf{page table base register} e \textbf{base table lenght register}, infatti la base table si trova in memoria contigua. Per velocizzare questa operazione si utilizza che TLB che \`e pi\`u piccola e si trova direttamente sulla CPU, si usa la \textbf{Translation Look-aside Buffer} (TLB), un tipo di memoria in cui si accede per contenuto. Si aggiunge anche un altra informazione \textbf{ASID} in cui viene salvata l'infromazione del processo a cui la pagina appartiene, se non \`e presente questa informazione si i processi si contentendono la TLB. Quando avviene un \textbf{TLB miss} se reinserisce nella TLB e poi si ritenta, utilizzando una politica scelta.
\begin{center}
  \emph{Lo schema finale \`e la combinazione di TLB e page table.}
\end{center}
Il \textbf{Tempo di accesso effettivo} (EAT) in memoria \`e il tempo che mi costa accedere alla RAM:
\[ EAT = h \cdot M + (1 - h) \cdot 2M  \]
\begin{itemize}
  \item $h$ = TLB hit ratio;
  \item $M$ = Memory access time;
\end{itemize}
La protezione \`e implementata associando un bit di protezione per un frame specifico, e quindi per la rispettiva pagina, grazie a questo bit si possono definire parti ci codice che indica che il frame \`e in solo scrittura. Anche un altro bit associato \`e \textbf{validity} che indica quando una pagina \`e valida, ovvero quando c'\`e ed \`e associata ad un frame, o quando una pagina non \`e valida che vuol dire che la pagina non esiste o che non \`e associata ad frame, se si cerca di accedere una pagina non valida viene lanciata una \textbf{trap}.

La tabella della pagina permette di \textbf{condividere le pagine} (anche se in realt\`a sono i frame), se pi\`u processi hanno delle pagine che sono comuni vengono condivise da entrambi i processi.

La page table \`e una struttura dati del kernel:
\begin{example}{}{}
  HP: spazio logico di indirizzamento di 32 bit, una pagina di 4KB ($2^{12}$), la page table avr\`a un milione di entry ($2^{32}/2^{12}$), ogni entry della page table sono 4bytes, quindi una pagetable \`e grande 4MB. Adesso \`e possibile avare:
  \begin{itemize}
    \item \textbf{page table contigua}:
      \begin{itemize}
        \item dimensione critica (troppo grande):
          \begin{itemize}
            \item page table gerarchica;
            \item hash page table;
            \item inverted page table;
          \end{itemize}
      \end{itemize}
  \end{itemize}
\end{example}
La \textbf{la page table gerarchica}, la page table viene divisa in blocchi pi\`u piccoli non contigui, se usa una page table di livello superiore che porte alle page table di livello inferiore, questi blocchi devono rimanere contigui, anche se diventano molto piccoli. Il page number viene diviso in due parti, una per la tabella outer ed una per la tabella inner (pu\`o avere anche pi\`u di due livelli), quando si va su 64 bit e la outer dienta molto grande si pu\`o usare solo una parte dell'indirizzamento se l'eseguibili \`e molto piccolo.

La \textbf{hashed page table} permette di creare una tabella di hash, con una funzione direttamente implementata in hardware che dato $p$ in input ritorna $f$. Vanno implementate delle liste di collisione, e quindi vieni immagazzinato che $p$ che \`e la chiave di accesso. Usando una tabella di hash si potrebbe pensare anche di usare una page table condivisa tra tutti i processi, ma a quel punto va inserito anche l'ID del processo.

La \textbf{inverted page table} \`e una tabella condivisa tra tutti i processi, la sua grandezza viene dimensionata sulla grandezza della RAM e non sulla grandezza dei processi, in cui ogni frame fisico \`e associata una pagina, in questo caso le entry che corrisponde ad un frame ritorna la pagina a cui \`e associto, il problema che si vuole la traduzione da pagine ad entry e non il contrario, la prima strategia che si pu\`o utilizzare \`e la scansione lineare. Per rendere l'accesso pi\`u veloce viene messa una tabella di hash prima di arrivare alla tabella invertita.


\subsection{Swapping}
Si suppunga che ad un certo punto si volgia far partire un processo e che la memoria sia piena, cosa si pu\`o fare? Una soluzione \`e lo \textbf{swapping}, ovvere viene rimesso sul backing store (in modo temporaneo) che in linux \`e la partizione di swap, e viene caricato il nuovo processo, grazie allo swapping si possono avere processi che hanno pi\`u memoria occupata di quanto la RAM sia grande.
\begin{example}{}{}
  Qunato costa il \textbf{context switch}? Memoria piena e viene fatto partire un programma, dunque deve essere portato un processo nel backing store. 100MB da fare la swap con velocit\`a di trasferimento di 50MB/sec.
  \begin{itemize}
    \item swap out = 2000ms
    \item pi\`u swap in dello stessa grandezza
    \item il tempo totole \`e di 4s
  \end{itemize}
  Se il porcesso sta fendo IO non si pu\`o fare lo swap out, una soluzione \`e non spostare un processo che sta facendo IO e spanane un altro, oppure usare un buffer del kernel.
\end{example}
Sui telefoni non esiste lo swaping, vengono in auito le \textbf{lifecycle dei contesti}. Il vantaggio di fare swapping \`e l'utilizzo del \textbf{paging swapping}, dove il swap in/out divento page in/out, dove vengono trasferite solo le pagine e non l'intero processo.

\subsection{Esercizi}
\begin{example}{}{}
  \begin{itemize}
    \item memoria fisica da 512MB
    \item allocazione minima 64B
    \item 128MB al SO
    \item tabella dei processi contiene: contiene indirizzo iniziale e size
    \item allocazione worst fit
    \item partizioni libere sono contenute in lista ordinata con dimensione descrescente
    \item 
  \end{itemize}
  Si supponga ...
\end{example}
\begin{example}{}{}
  Si descrivano brevemente 
  \begin{itemize}
    \item tlb: 0.9 hit ratio
    \item page table a due livelli
    \item indirizzo in tre parti, 10 11 11 bit
    \item 
  \end{itemize}
  Si fa una outer con cui si utillizzano 10bit, ed una inner con 11bit. Per calcolare il numero di inner ci sono due strade, il numero di byte preciso che contengono 100MB oppure si prende la prima potenza di 2 che contiene 100MB. Il resto delle righe delle outer overanno l'invalid bit settato ad 1.
\end{example}



\section{Memoria Virtuale}
Con \textbf{memoria virtuale} si indica che delle pagine esistono solo virtualemente ma non fisicamente, in questo modo si vuole supportare uno spazio di indirizzamento pi\`u grande dello spazio di indirizzamento fisico. Si parte dalla premessa che \emph{un programma non bisogna di essere tutto in memoria per essere esguito}, si pensa ad un programma parzialmente caricato in memoria, dunque le mamoria di un programma non \`e pi\`u vincolato dalla grandezza della RAM, in questo caso si parla di \textbf{memoria virtuale}. Avere questa memoria virtuale porta una serie di vantaggi che volocizzano tutte le operazioni di IO tra la RAM e la memoria secondaria. La conseguenza \`e che viene introdotta la \textbf{demand paging}, ovvero che un pagina viene caricata solo quando \`e richiesta. Il \textbf{demand paging} \`e molto simile allo swapping, infatti il caso limite \`e il \textbf{lazy swapper} dove inizialmente non si ha nessun frame caricato, e ogni richiesta viene preso un frame.






\section{Rust}


Come in kotlin i blocchi condizionali hanno dei valori di ritorno. In rust non esiste l'eriditarit\`a, per\`o esistono i \textbf{trait}, che sono simili alle interfacce, offrendo la possibilit\`a di poter implementare dei metodi, ad esempio alcuni di questi sono \texttt{Display} e \texttt{Debug}, ogni tipo pu\`o implementare pi\`u tratti.

I tipi elementari di rust sono:
\begin{itemize}
  \item numerici: \texttt{i8, i16, i32, i64, i128, isize} (valore nativo del processore).
  \item numerici senza segno: \texttt{u8, ...}
  \item naturali: \texttt{f32, f64}
  \item logici: \texttt{bool}
  \item caratteri: \texttt{char} (32 bit, rappresentazione \textbf{Unicode})
  \item unit: \texttt{()} rappresenta una tupla di 0 elementi, corrisponde a \texttt{void} in C/C++
\end{itemize}
Per rappresentare le stringhe invece si use la codifica \texttt{utf-8}, che codifica i caratteri unicode in blocchi di 8 bit, la codifica utilizza la maggior parte dei primi 8 bit come caratteri standard, se si vogliono usare simboli pi\`u strani si combina un byte con il successivo, se il carattere \`e ancora pi\`u raro si utilizzano pi\`u byte, fino ad arrivare a 4.

Una tupla \`e una struttura che permette di contenere pi\`u tipi di valori, per accedere alla posizione corrispondente si utilizza la notazoine \texttt{.<numero>}.

Rust ha un meccanismo al suo interno per rappresentare i puntatori, infatti quando viene creato un valore in una funzione si pu\`o decidere di passare la propri\`a di questo alla funzione chiamante, che poi ha la responsabilit\`a di liberla oppure di passare ancora il possesso, in rust esistono tre tipi di puntatori:
\begin{itemize}
  \item \textbf{reference};
  \item \textbf{box};
  \item \textbf{native pointer};
\end{itemize}
Per utilizzare i puntatori nativi (che sono gli stessi del C), possono essere solo utilizzati in un blocco \texttt{unsafe { ... }}.

Le \textbf{reference} sono puntatori senza possesso e possono essere assegnati con \texttt{&}:
\begin{lstlisting}[language=]
let r1 = &v;
let r1 = &mut v;
\end{lstlisting}
In questo caso \texttt{r1} borrows il valore \texttt{v}, per acceder al valore si utilizza la notazione per \textbf{derefenziare}: \texttt{*r1}. Quando si crea un puntatore che \texttt{&} si pu\`o un creare un puntatore in sola lettura, si vuole anche scrivere all'indirizzo del puntatore si deve usere la keyword mut: \texttt{&mut v}, l'accesso in scrittura \`e \emph{esclusivo}, ovvero pu\`o essere assegnato ad una sola variabile e quando viene asseganto in modo mutabile nussun altro pu\`o utilizzarlo, infatti \`e \emph{mutuamente esclusivo}.
\begin{lstlisting}[language=]
fn main() {
  let mut i = 32;

  let r = &i;     // r is of type "int ref";
  println!("{}", *r);

  i = i+1;        // ERROR: i was borrwed
  println!("{}", *r);
}
\end{lstlisting}
\begin{lstlisting}[language=]
fn main() {
  let mut i = 32;

  let r = &mut i;
  println!("{}", i);  // ERROR: i was mutably borrowed

  *r = *r+1;
  println!("{}", *r);
}
\end{lstlisting}
In questo caso la variabile \texttt{i} non \`e accessibile in alcun modo per tutta l'esistenza di \texttt{r}.

In altre situazioni c'\`e l'esigenza di allocare un dato, per prolungare la sua vita all'infuori della funzione in cui viene creato, l'equivalente della \texttt{malloc} in rust \`e \texttt{Box<T>} che alloca un parte di memoria presa dall'\emph{heap}, per creare un valore che che si vuole venga conservato, si passa a \texttt{Box} il valore che voglio si venga conservato:
\begin{lstlisting}[language=]
let b = Box::new(v);
\end{lstlisting}
Rust \`e in grado di fare l'infer del tipo di \texttt{v} e riesce ad allocare lo spazio necessario, quando \texttt{b} non sar\`a pi\`u visibile il \texttt{Box} verr\`a liberato dalla memoria.
\begin{lstlisting}[language=]
fn useBox() {
  let i = 4;                      // i si trova nello stack
  let mub b = Box::new((5, 2));   // *b si trova nell'heap, b si trova nello stack

  (*b).1 = 7;

  println!("{:?}", *b);   // (5, 7)
  println!("{:?}", b);    // (5, 7)
}
\end{lstlisting}
Quando \texttt{println!} si trova un puntatore lo dereferenzia automaticamente. Quando si arriva alla fine della funzione \texttt{a} e \texttt{b} vengono rimossi dallo stack, dato che il valore a cui puntava \texttt{b} non possiede un owner in vista quel valore viene rimosso dell'heap.
\begin{lstlisting}[language=]
fn makeBox(a: i32) -> Box<(i32,i32)> {
  let r = Box::new((a, 1));
  return r;
}

fn main() {
  let b = makeBox(5);
  let c = b.0 + b.1;
}
\end{lstlisting}
In questo caso il valore l'ownership del valore puntato da \texttt{r} passa la sua ownership a \texttt{b} che si trova nel \texttt{main}, quando il \texttt{main} termina e la vita di \texttt{b} finise il valore puntato viene anch'esso liberato.





















\end{document}

